{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76481da1",
   "metadata": {},
   "source": [
    "# Federated Learning on CIFAR-10: Data Exploration and Results Analysis\n",
    "\n",
    "This notebook provides a comprehensive overview of the data and results for federated learning experiments (FedAvg and FedProx) on CIFAR-10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391b1201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from collections import Counter\n",
    "display_available = True\n",
    "try:\n",
    "    from IPython.display import display\n",
    "except ImportError:\n",
    "    display_available = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cc6173",
   "metadata": {},
   "source": [
    "## 1. Dataset Overview and Visualization\n",
    "\n",
    "Explore the CIFAR-10 dataset: class distribution and sample images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0959a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CIFAR-10 dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "trainset = datasets.CIFAR10(root=\"../data\", train=True, download=True, transform=transform)\n",
    "classes = trainset.classes\n",
    "labels = np.array(trainset.targets)\n",
    "\n",
    "# Plot class distribution\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.countplot(x=labels)\n",
    "plt.title(\"CIFAR-10 Class Distribution (Train)\")\n",
    "plt.xticks(ticks=range(10), labels=classes, rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# Show sample images per class\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12,5))\n",
    "for i, cls in enumerate(classes):\n",
    "    idx = np.where(labels == i)[0][0]  # Get the first index for class i\n",
    "    img = trainset.data[idx]\n",
    "    axes[i//5, i%5].imshow(img)\n",
    "    axes[i//5, i%5].set_title(cls)\n",
    "    axes[i//5, i%5].axis('off')\n",
    "plt.suptitle(\"Sample Images per Class\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc8de01",
   "metadata": {},
   "source": [
    "## 2. Data Partitioning: IID vs Non-IID\n",
    "\n",
    "Visualize how data is split among clients for both IID and non-IID settings. Show class distribution for each client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50d51f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Non-IID partitioning (2 classes per client)\n",
    "from collections import defaultdict\n",
    "num_clients = 10\n",
    "classes_per_client = 2\n",
    "np.random.seed(42)\n",
    "labels = np.array(trainset.targets)\n",
    "class_indices = [np.where(labels == i)[0] for i in range(10)]\n",
    "client_indices = [[] for _ in range(num_clients)]\n",
    "all_classes = np.arange(10)\n",
    "for client in range(num_clients):\n",
    "    chosen_classes = np.random.choice(all_classes, classes_per_client, replace=False)\n",
    "    for cls in chosen_classes:\n",
    "        idxs = np.random.choice(class_indices[cls], len(class_indices[cls]) // num_clients, replace=False)\n",
    "        client_indices[client].extend(idxs)\n",
    "        class_indices[cls] = np.setdiff1d(class_indices[cls], idxs)\n",
    "\n",
    "# Plot class distribution per client\n",
    "fig, axes = plt.subplots(2, 5, figsize=(16,6), sharey=True)\n",
    "for client in range(num_clients):\n",
    "    client_labels = labels[client_indices[client]]\n",
    "    counts = [np.sum(client_labels == i) for i in range(10)]\n",
    "    ax = axes[client//5, client%5]\n",
    "    ax.bar(range(10), counts)\n",
    "    ax.set_xticks(range(10))\n",
    "    ax.set_xticklabels(classes, rotation=45, fontsize=8)\n",
    "    ax.set_title(f\"Client {client}\")\n",
    "plt.suptitle(\"Class Distribution per Client (Non-IID)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e13b82",
   "metadata": {},
   "source": [
    "## 3. Data Integrity Checks and Summary\n",
    "\n",
    "Check for data leakage, print number of samples per client, and show summary statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3071fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for data leakage (overlap between clients)\n",
    "all_indices = np.concatenate(client_indices)\n",
    "unique_indices = np.unique(all_indices)\n",
    "print(f\"Total samples assigned: {len(all_indices)}\")\n",
    "print(f\"Unique samples assigned: {len(unique_indices)}\")\n",
    "if len(all_indices) == len(unique_indices):\n",
    "    print(\"No data leakage detected (no overlap between clients).\")\n",
    "else:\n",
    "    print(\"Warning: Data leakage detected!\")\n",
    "\n",
    "# Print number of samples per client\n",
    "for client in range(num_clients):\n",
    "    print(f\"Client {client}: {len(client_indices[client])} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93c45ff",
   "metadata": {},
   "source": [
    "## 4. Training and Test Curves: FedAvg vs FedProx\n",
    "\n",
    "Plot accuracy and loss vs. communication rounds for both algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7234bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load experiment logs (assume CSVs saved by each experiment)\n",
    "fedavg_log = pd.read_csv(\"../results/fedavg_metrics.csv\")\n",
    "fedprox_log = pd.read_csv(\"../results/fedprox_metrics.csv\")\n",
    "\n",
    "# Plot accuracy vs. communication rounds\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(fedavg_log[\"accuracy\"], label=\"FedAvg\")\n",
    "plt.plot(fedprox_log[\"accuracy\"], label=\"FedProx\")\n",
    "plt.title(\"Test Accuracy vs Communication Rounds\")\n",
    "plt.xlabel(\"Round\")\n",
    "plt.ylabel(\"Test Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot loss vs. communication rounds\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(fedavg_log[\"loss\"], label=\"FedAvg\")\n",
    "plt.plot(fedprox_log[\"loss\"], label=\"FedProx\")\n",
    "plt.title(\"Test Loss vs Communication Rounds\")\n",
    "plt.xlabel(\"Round\")\n",
    "plt.ylabel(\"Test Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbff863",
   "metadata": {},
   "source": [
    "## 5. Per-Client Performance\n",
    "\n",
    "Analyze and visualize accuracy/loss per client to show heterogeneity effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6e88b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot per-client accuracy (if available)\n",
    "if \"client_accuracies\" in fedavg_log.columns and \"client_accuracies\" in fedprox_log.columns:\n",
    "    fedavg_client_acc = fedavg_log[\"client_accuracies\"].apply(eval).tolist()  # list of lists\n",
    "    fedprox_client_acc = fedprox_log[\"client_accuracies\"].apply(eval).tolist()\n",
    "    rounds = len(fedavg_client_acc)\n",
    "    num_clients = len(fedavg_client_acc[0])\n",
    "    plt.figure(figsize=(10,6))\n",
    "    for client in range(num_clients):\n",
    "        plt.plot([fedavg_client_acc[r][client] for r in range(rounds)], label=f\"FedAvg Client {client}\", alpha=0.5)\n",
    "    plt.title(\"FedAvg: Per-Client Accuracy vs Rounds\")\n",
    "    plt.xlabel(\"Round\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)\n",
    "    plt.show()\n",
    "    plt.figure(figsize=(10,6))\n",
    "    for client in range(num_clients):\n",
    "        plt.plot([fedprox_client_acc[r][client] for r in range(rounds)], label=f\"FedProx Client {client}\", alpha=0.5)\n",
    "    plt.title(\"FedProx: Per-Client Accuracy vs Rounds\")\n",
    "    plt.xlabel(\"Round\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Per-client accuracy not available in logs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883bdf90",
   "metadata": {},
   "source": [
    "## 6. Confusion Matrix and Misclassified Images\n",
    "\n",
    "Visualize confusion matrix and show examples of misclassified images for the final global model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a73fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Compute and plot confusion matrix for final FedAvg model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, title='Confusion matrix'):\n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# Assume y_true and y_pred are available from test set evaluation\n",
    "y_true = fedavg_log.get('y_true', None)\n",
    "y_pred = fedavg_log.get('y_pred', None)\n",
    "if y_true is not None and y_pred is not None:\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plot_confusion_matrix(cm, classes)\n",
    "else:\n",
    "    print(\"Confusion matrix data not available in logs.\")\n",
    "\n",
    "# Show misclassified images (if available)\n",
    "# Assume misclassified = list of (img, true_label, pred_label)\n",
    "misclassified = fedavg_log.get('misclassified', None)\n",
    "if misclassified is not None:\n",
    "    n = min(10, len(misclassified))\n",
    "    fig, axes = plt.subplots(1, n, figsize=(15,3))\n",
    "    for i in range(n):\n",
    "        img, true_label, pred_label = misclassified[i]\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].set_title(f\"T:{classes[true_label]}\\nP:{classes[pred_label]}\")\n",
    "        axes[i].axis('off')\n",
    "    plt.suptitle(\"Examples of Misclassified Images (FedAvg)\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Misclassified images not available in logs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e7664b",
   "metadata": {},
   "source": [
    "## 7. Experiment Configuration and Reproducibility\n",
    "\n",
    "Display all experiment parameters and random seeds used for each run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8e65ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display experiment configuration\n",
    "import yaml\n",
    "with open(\"../config/fedavg_config.yaml\") as f:\n",
    "    fedavg_cfg = yaml.safe_load(f)\n",
    "with open(\"../config/fedprox_config.yaml\") as f:\n",
    "    fedprox_cfg = yaml.safe_load(f)\n",
    "print(\"FedAvg Config:\")\n",
    "print(fedavg_cfg)\n",
    "print(\"\\nFedProx Config:\")\n",
    "print(fedprox_cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80e9dd9",
   "metadata": {},
   "source": [
    "## 8. Summary Table of Results\n",
    "\n",
    "Tabulate key results (final accuracy, rounds to reach target accuracy, etc.) for all algorithms/settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda694cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary table of results\n",
    "summary = {\n",
    "    \"Algorithm\": [\"FedAvg\", \"FedProx\"],\n",
    "    \"Final Accuracy\": [fedavg_log[\"accuracy\"].iloc[-1], fedprox_log[\"accuracy\"].iloc[-1]],\n",
    "    \"Best Accuracy\": [fedavg_log[\"accuracy\"].max(), fedprox_log[\"accuracy\"].max()],\n",
    "    \"Rounds to 70% Acc\": [next((i for i, acc in enumerate(fedavg_log[\"accuracy\"]) if acc >= 0.7), None),\n",
    "                          next((i for i, acc in enumerate(fedprox_log[\"accuracy\"]) if acc >= 0.7), None)]\n",
    "}\n",
    "df_summary = pd.DataFrame(summary)\n",
    "display(df_summary) if display_available else print(df_summary)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
